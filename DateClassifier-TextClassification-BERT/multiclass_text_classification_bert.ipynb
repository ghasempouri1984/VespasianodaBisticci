{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGnlRWvkY-2c"
      },
      "source": [
        "# Multi-Class Text Classification for building Date Classifier with BERT\n",
        "\n",
        "> In this notebook, I tried to use tex classification with BERT for predicting Dates of letters. I start with text preprocessing (special tokens, padding, and attention masks) and build a Date Classifier using the Transformers. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJ6MhJYYBCwu",
        "outputId": "45bc4f3f-4a12-45d1-ac41-14d7f8f1d1cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Dec  8 22:22:30 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  A100-SXM4-40GB      Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   30C    P0    52W / 400W |      0MiB / 40536MiB |      0%      Default |\n",
            "|                               |                      |             Disabled |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyzBkxM4tap_",
        "outputId": "2174c984-fb74-457c-840b-5b6a36679d01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmj22-TcZMef"
      },
      "source": [
        "## Setup\n",
        "\n",
        "We'll need [the Transformers library](https://huggingface.co/transformers/) by Hugging Face:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "Kj_7Tz0-pK69"
      },
      "outputs": [],
      "source": [
        "# !pip install -q -U watermark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "Jjsbi1u3QFEM"
      },
      "outputs": [],
      "source": [
        "!pip install -qq transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJqoaFpVpoM8",
        "outputId": "292147e5-f8fb-426e-9764-18ec427408d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python implementation: CPython\n",
            "Python version       : 3.8.15\n",
            "IPython version      : 7.9.0\n",
            "\n",
            "numpy       : 1.21.6\n",
            "pandas      : 1.3.5\n",
            "torch       : 1.13.0+cu116\n",
            "transformers: 4.25.1\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# %reload_ext watermark\n",
        "# %watermark -v -p numpy,pandas,torch,transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w68CZpOwFoly",
        "outputId": "70d72858-2995-456c-dc74-7a676517f561"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ],
      "source": [
        "#@title Setup & Config\n",
        "import transformers\n",
        "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
        "import torch\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from collections import defaultdict\n",
        "from textwrap import wrap\n",
        "\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format='retina'\n",
        "\n",
        "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
        "\n",
        "HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\n",
        "\n",
        "sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n",
        "\n",
        "rcParams['figure.figsize'] = 12, 8\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# device = torch.device(\"cuda\")\n",
        "\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufzPdoTtNikq"
      },
      "source": [
        "## Data Exploration\n",
        "\n",
        "We'll load the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "mUKLyKc7I6Qp",
        "outputId": "c3fe791f-c9b4-4190-9b11-4f3924a77b16"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                         sender                         addressee  \\\n",
              "0  Iacopo Ammannati Piccolomini            Vespasiano da Bisticci   \n",
              "1             Donato Acciaiuoli            Vespasiano da Bisticci   \n",
              "2        Vespasiano da Bisticci                Filippo Podocataro   \n",
              "3        Vespasiano da Bisticci                Filippo Podocataro   \n",
              "4        Vespasiano da Bisticci  Iohannes Caldarifex de Monthabur   \n",
              "\n",
              "          from                                              testo  date  \\\n",
              "0  Montegufoni  James, cardinal of Papia , greets Vespasian .\\...  1444   \n",
              "1  Montegufoni  Vespasiano mio dolcissimo, le lettere le quali...  1446   \n",
              "2      Firenze  Vehementer me oblectant littere tue, Philippe ...  1444   \n",
              "3      Firenze  Paucis ante diebus respondidi litteris tuis, P...  1448   \n",
              "4      Firenze  Suscepi nuper litteras tuas, quibus nescio qui...  1448   \n",
              "\n",
              "   lettere  \n",
              "0       41  \n",
              "1        1  \n",
              "2        2  \n",
              "3        3  \n",
              "4        4  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-229580b8-e888-43f8-ae9c-4ce65f4613fa\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sender</th>\n",
              "      <th>addressee</th>\n",
              "      <th>from</th>\n",
              "      <th>testo</th>\n",
              "      <th>date</th>\n",
              "      <th>lettere</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Iacopo Ammannati Piccolomini</td>\n",
              "      <td>Vespasiano da Bisticci</td>\n",
              "      <td>Montegufoni</td>\n",
              "      <td>James, cardinal of Papia , greets Vespasian .\\...</td>\n",
              "      <td>1444</td>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Donato Acciaiuoli</td>\n",
              "      <td>Vespasiano da Bisticci</td>\n",
              "      <td>Montegufoni</td>\n",
              "      <td>Vespasiano mio dolcissimo, le lettere le quali...</td>\n",
              "      <td>1446</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Vespasiano da Bisticci</td>\n",
              "      <td>Filippo Podocataro</td>\n",
              "      <td>Firenze</td>\n",
              "      <td>Vehementer me oblectant littere tue, Philippe ...</td>\n",
              "      <td>1444</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Vespasiano da Bisticci</td>\n",
              "      <td>Filippo Podocataro</td>\n",
              "      <td>Firenze</td>\n",
              "      <td>Paucis ante diebus respondidi litteris tuis, P...</td>\n",
              "      <td>1448</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Vespasiano da Bisticci</td>\n",
              "      <td>Iohannes Caldarifex de Monthabur</td>\n",
              "      <td>Firenze</td>\n",
              "      <td>Suscepi nuper litteras tuas, quibus nescio qui...</td>\n",
              "      <td>1448</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-229580b8-e888-43f8-ae9c-4ce65f4613fa')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-229580b8-e888-43f8-ae9c-4ce65f4613fa button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-229580b8-e888-43f8-ae9c-4ce65f4613fa');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ],
      "source": [
        "# df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/dati/rows.csv\")\n",
        "\n",
        "# df = pd.read_csv(\"./Data/rows.csv\")\n",
        "# df.head(1)\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/dati/Book1Copy.csv\")\n",
        "df.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dB2jE6am7Dpo",
        "outputId": "3db9ab46-ec35-449d-eb0c-079a7cce93f3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(23, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWqVNHJbn10l"
      },
      "source": [
        "Let's check for missing values:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VA_wGSLQLKCh",
        "outputId": "a7173481-431b-4d67-edd5-bdc7549c1089"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 23 entries, 0 to 22\n",
            "Data columns (total 6 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   sender     23 non-null     object\n",
            " 1   addressee  23 non-null     object\n",
            " 2   from       23 non-null     object\n",
            " 3   testo      23 non-null     object\n",
            " 4   date       23 non-null     int64 \n",
            " 5   lettere    23 non-null     int64 \n",
            "dtypes: int64(2), object(4)\n",
            "memory usage: 1.2+ KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.astype(object)"
      ],
      "metadata": {
        "id": "dwJSBYxC0e2o"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLXjVaCH0kDz",
        "outputId": "965f3863-1ee6-4ad4-8a68-eb346d22073d"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 23 entries, 0 to 22\n",
            "Data columns (total 6 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   sender     23 non-null     object\n",
            " 1   addressee  23 non-null     object\n",
            " 2   from       23 non-null     object\n",
            " 3   testo      23 non-null     object\n",
            " 4   date       23 non-null     object\n",
            " 5   lettere    23 non-null     object\n",
            "dtypes: object(6)\n",
            "memory usage: 1.2+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "tHCt2wfXxLAI"
      },
      "outputs": [],
      "source": [
        "# Create a new dataframe with two columns\n",
        "train_raw = df[['testo', 'date']].copy()\n",
        "\n",
        "# Remove missing values (NaN)\n",
        "train_raw = train_raw[pd.notnull(train_raw['testo'])]\n",
        "\n",
        "# Renaming second column for a simpler name\n",
        "# train_raw.columns = ['', '']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "A4JnIhPAxx8P",
        "outputId": "2d36a2b7-8ae4-45e3-a8b1-cbd55b9c90b2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           len_txt\n",
              "count    23.000000\n",
              "mean    296.695652\n",
              "std     263.342576\n",
              "min      62.000000\n",
              "25%     156.000000\n",
              "50%     214.000000\n",
              "75%     309.000000\n",
              "max    1278.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c70a8a0c-ec1d-4d18-8609-19bf94519178\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>len_txt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>23.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>296.695652</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>263.342576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>62.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>156.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>214.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>309.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1278.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c70a8a0c-ec1d-4d18-8609-19bf94519178')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c70a8a0c-ec1d-4d18-8609-19bf94519178 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c70a8a0c-ec1d-4d18-8609-19bf94519178');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ],
      "source": [
        "# train_raw = train_raw[train_raw.testo.notnull()]\n",
        "\n",
        "train_raw['len_txt'] =train_raw.testo.apply(lambda x: len(x.split()))\n",
        "train_raw.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "tu1r8Um5xxuG",
        "outputId": "25df2132-c859-44e4-a83d-6637b201a0ec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           len_txt\n",
              "count    23.000000\n",
              "mean    296.695652\n",
              "std     263.342576\n",
              "min      62.000000\n",
              "25%     156.000000\n",
              "50%     214.000000\n",
              "75%     309.000000\n",
              "max    1278.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-00491536-1483-4e2a-b199-54c416857d83\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>len_txt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>23.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>296.695652</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>263.342576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>62.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>156.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>214.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>309.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1278.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-00491536-1483-4e2a-b199-54c416857d83')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-00491536-1483-4e2a-b199-54c416857d83 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-00491536-1483-4e2a-b199-54c416857d83');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ],
      "source": [
        "train_raw = train_raw[train_raw.len_txt >50]\n",
        "train_raw.describe()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_raw"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 771
        },
        "id": "-E6x2-igDmnK",
        "outputId": "1803ac40-4918-43f9-a777-2be28bb84b07"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                testo  date  len_txt\n",
              "0   James, cardinal of Papia , greets Vespasian .\\...  1444      302\n",
              "1   Vespasiano mio dolcissimo, le lettere le quali...  1446      173\n",
              "2   Vehementer me oblectant littere tue, Philippe ...  1444      180\n",
              "3   Paucis ante diebus respondidi litteris tuis, P...  1448       79\n",
              "4   Suscepi nuper litteras tuas, quibus nescio qui...  1448      139\n",
              "5   Quamquam impresentiarum nihil haberem quod ad ...  1446      118\n",
              "6   Ad epistolam tuam nuper accepi mihi impresenti...  1446      205\n",
              "7   Reverende in Christo pater et domine mi singul...  1449      142\n",
              "8   Egli è più dì ch'io ricevetti una tua, alla qu...  1449     1278\n",
              "9   Dici non potest, Vespasiane suavissime, quantu...  1450      747\n",
              "10  Honorevole come fratello et caetera. Ne' dì pa...  1450      316\n",
              "11  Egregie tanquam frater carissime. Perché dite ...  1444      208\n",
              "12  Egregie tanquam frater, ho ricevuta vostra let...  1446      279\n",
              "13  Alla tua de dì 15 di questo acchade brieve ris...  1448      495\n",
              "14  Il primo et solo de' nostri ch'io avisassi com...  1449      391\n",
              "15  Avendo ne' giorni passati facto risposta a una...  1450      449\n",
              "16  Poiché ne' giorni passati ti scripsi del gran ...  1444      240\n",
              "17  Honorevole come fratello et cetera. Quanto più...  1446      257\n",
              "18  Egli sono più dì ch'io avevo finita la prima D...  1448      214\n",
              "19  Il Prinio è finito di miniare, e di tucto hall...  1449      170\n",
              "20  Il Prinio e lla Decha sono di tutto finiti in ...  1450       62\n",
              "21  Reverende in Christo Pater et Domine, humili c...  1448      257\n",
              "22  Suscepi, una cum litteris tuis, Philippicas Ci...  1450      123"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5ee4f856-d788-44e0-a640-4e13b85ff8fa\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>testo</th>\n",
              "      <th>date</th>\n",
              "      <th>len_txt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>James, cardinal of Papia , greets Vespasian .\\...</td>\n",
              "      <td>1444</td>\n",
              "      <td>302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Vespasiano mio dolcissimo, le lettere le quali...</td>\n",
              "      <td>1446</td>\n",
              "      <td>173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Vehementer me oblectant littere tue, Philippe ...</td>\n",
              "      <td>1444</td>\n",
              "      <td>180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Paucis ante diebus respondidi litteris tuis, P...</td>\n",
              "      <td>1448</td>\n",
              "      <td>79</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Suscepi nuper litteras tuas, quibus nescio qui...</td>\n",
              "      <td>1448</td>\n",
              "      <td>139</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Quamquam impresentiarum nihil haberem quod ad ...</td>\n",
              "      <td>1446</td>\n",
              "      <td>118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Ad epistolam tuam nuper accepi mihi impresenti...</td>\n",
              "      <td>1446</td>\n",
              "      <td>205</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Reverende in Christo pater et domine mi singul...</td>\n",
              "      <td>1449</td>\n",
              "      <td>142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Egli è più dì ch'io ricevetti una tua, alla qu...</td>\n",
              "      <td>1449</td>\n",
              "      <td>1278</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Dici non potest, Vespasiane suavissime, quantu...</td>\n",
              "      <td>1450</td>\n",
              "      <td>747</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Honorevole come fratello et caetera. Ne' dì pa...</td>\n",
              "      <td>1450</td>\n",
              "      <td>316</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Egregie tanquam frater carissime. Perché dite ...</td>\n",
              "      <td>1444</td>\n",
              "      <td>208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Egregie tanquam frater, ho ricevuta vostra let...</td>\n",
              "      <td>1446</td>\n",
              "      <td>279</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Alla tua de dì 15 di questo acchade brieve ris...</td>\n",
              "      <td>1448</td>\n",
              "      <td>495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Il primo et solo de' nostri ch'io avisassi com...</td>\n",
              "      <td>1449</td>\n",
              "      <td>391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Avendo ne' giorni passati facto risposta a una...</td>\n",
              "      <td>1450</td>\n",
              "      <td>449</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Poiché ne' giorni passati ti scripsi del gran ...</td>\n",
              "      <td>1444</td>\n",
              "      <td>240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Honorevole come fratello et cetera. Quanto più...</td>\n",
              "      <td>1446</td>\n",
              "      <td>257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Egli sono più dì ch'io avevo finita la prima D...</td>\n",
              "      <td>1448</td>\n",
              "      <td>214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Il Prinio è finito di miniare, e di tucto hall...</td>\n",
              "      <td>1449</td>\n",
              "      <td>170</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Il Prinio e lla Decha sono di tutto finiti in ...</td>\n",
              "      <td>1450</td>\n",
              "      <td>62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Reverende in Christo Pater et Domine, humili c...</td>\n",
              "      <td>1448</td>\n",
              "      <td>257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Suscepi, una cum litteris tuis, Philippicas Ci...</td>\n",
              "      <td>1450</td>\n",
              "      <td>123</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5ee4f856-d788-44e0-a640-4e13b85ff8fa')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5ee4f856-d788-44e0-a640-4e13b85ff8fa button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5ee4f856-d788-44e0-a640-4e13b85ff8fa');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "years=train_raw.date.values.tolist()\n",
        "# year_names = ['1444', '1446', '1448', '1449', '1450']\n",
        "\n",
        "train_raw['letter_date'] = years"
      ],
      "metadata": {
        "id": "oUtWzDcs-6eS"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "K6T32BhlyIdL",
        "outputId": "0474e039-2532-424f-e8a8-71e96531d4f1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               testo  letter_date\n",
              "0  James, cardinal of Papia , greets Vespasian .\\...         1444\n",
              "1  Vespasiano mio dolcissimo, le lettere le quali...         1446"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bea4b1b8-7e4d-493f-a2fa-c55f008c98a6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>testo</th>\n",
              "      <th>letter_date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>James, cardinal of Papia , greets Vespasian .\\...</td>\n",
              "      <td>1444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Vespasiano mio dolcissimo, le lettere le quali...</td>\n",
              "      <td>1446</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bea4b1b8-7e4d-493f-a2fa-c55f008c98a6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bea4b1b8-7e4d-493f-a2fa-c55f008c98a6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bea4b1b8-7e4d-493f-a2fa-c55f008c98a6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ],
      "source": [
        "train_raw = train_raw[['testo', 'letter_date']]\n",
        "train_raw.reset_index(inplace=True, drop=True)\n",
        "# train_raw[\"date\"] = pd.to_datetime(train_raw[\"date\"]).dt.strftime('%Y')\n",
        "\n",
        "train_raw.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "Zwrgzw0ey3BJ"
      },
      "outputs": [],
      "source": [
        "df2 = train_raw.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "bs-aVGxZy20q"
      },
      "outputs": [],
      "source": [
        "df2 = df2.reindex(np.random.permutation(df2.index))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cleaning the text:"
      ],
      "metadata": {
        "id": "pkHICpqB2h4J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "9-hE1ld4yIKk"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "def clean_txt(text):\n",
        "  text = re.sub(\"'\", \"\",text)\n",
        "  text=re.sub(\"(\\\\W)+\",\" \",text)\n",
        "  return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "_Rng6GFMzHGz",
        "outputId": "46291eec-8c75-4bd8-c4d9-ce2c6fb312ab"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                testo  letter_date\n",
              "15  Avendo ne giorni passati facto risposta a una ...         1450\n",
              "9   Dici non potest Vespasiane suavissime quantum ...         1450\n",
              "0   James cardinal of Papia greets Vespasian Dear ...         1444\n",
              "8   Egli è più dì chio ricevetti una tua alla qual...         1449\n",
              "17  Honorevole come fratello et cetera Quanto più ...         1446"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-95e921ff-4a70-4c6c-983b-dfdca658ab4e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>testo</th>\n",
              "      <th>letter_date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Avendo ne giorni passati facto risposta a una ...</td>\n",
              "      <td>1450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Dici non potest Vespasiane suavissime quantum ...</td>\n",
              "      <td>1450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>James cardinal of Papia greets Vespasian Dear ...</td>\n",
              "      <td>1444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Egli è più dì chio ricevetti una tua alla qual...</td>\n",
              "      <td>1449</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Honorevole come fratello et cetera Quanto più ...</td>\n",
              "      <td>1446</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-95e921ff-4a70-4c6c-983b-dfdca658ab4e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-95e921ff-4a70-4c6c-983b-dfdca658ab4e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-95e921ff-4a70-4c6c-983b-dfdca658ab4e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ],
      "source": [
        "df2['testo']  = df2.testo.apply(clean_txt)\n",
        "df2.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "8chGNZWOzlfE",
        "outputId": "9b65be9f-bed6-4e02-c8f8-16ceaed9575e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               testo  letter_date\n",
              "0  Avendo ne giorni passati facto risposta a una ...         1450\n",
              "1  Dici non potest Vespasiane suavissime quantum ...         1450\n",
              "2  James cardinal of Papia greets Vespasian Dear ...         1444\n",
              "3  Egli è più dì chio ricevetti una tua alla qual...         1449\n",
              "4  Honorevole come fratello et cetera Quanto più ...         1446"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0bdf82d4-a29a-4ec8-9ebc-bf8b3e7414cf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>testo</th>\n",
              "      <th>letter_date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Avendo ne giorni passati facto risposta a una ...</td>\n",
              "      <td>1450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Dici non potest Vespasiane suavissime quantum ...</td>\n",
              "      <td>1450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>James cardinal of Papia greets Vespasian Dear ...</td>\n",
              "      <td>1444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Egli è più dì chio ricevetti una tua alla qual...</td>\n",
              "      <td>1449</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Honorevole come fratello et cetera Quanto più ...</td>\n",
              "      <td>1446</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0bdf82d4-a29a-4ec8-9ebc-bf8b3e7414cf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0bdf82d4-a29a-4ec8-9ebc-bf8b3e7414cf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0bdf82d4-a29a-4ec8-9ebc-bf8b3e7414cf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ],
      "source": [
        "df2.reset_index(drop=True, inplace=True)\n",
        "df2.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.11.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 94
        }
      ],
      "source": [
        "from importlib.metadata import version\n",
        "version('seaborn')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "uhnrmMZz4UDV",
        "outputId": "95510104-2eef-42eb-a488-bc344a68501f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "Wwh_rW4Efhs3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "b804318b-1baf-49c1-d1b2-169b97a6d859"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "image/png": {
              "width": 719,
              "height": 489
            }
          }
        }
      ],
      "source": [
        "sns.countplot(df2.letter_date)\n",
        "plt.xlabel('letter year');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZM0GKviobjM"
      },
      "source": [
        "It was highly imbalanced, \n",
        "but I changed the csv manually before to have a balanced data. I faced problems with imbalanced classfication. Here the dataset is converted into different years:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYHvfkYf1iNZ",
        "outputId": "ed566eeb-0ed6-453a-fdc1-3d534d2db460"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1450: 0, 1444: 1, 1449: 2, 1446: 3, 1448: 4}"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ],
      "source": [
        "possible_labels = df2.letter_date.unique()\n",
        "\n",
        "label_dict = {}\n",
        "for index, possible_label in enumerate(possible_labels):\n",
        "    label_dict[possible_label] = index\n",
        "label_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "MbltzMbJ1xaQ"
      },
      "outputs": [],
      "source": [
        "class_names = ['1450', '1444', '1449', '1446', '1448']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "y3tY3ECJDPaz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "a785a848-fefe-47d9-898a-0fa0eac86194"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "image/png": {
              "width": 719,
              "height": 489
            }
          }
        }
      ],
      "source": [
        "ax = sns.countplot(df2.letter_date)\n",
        "plt.xlabel(' letter year')\n",
        "ax.set_xticklabels(class_names);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "JKPeiklh2-IM",
        "outputId": "e8942c70-1b6c-4ba4-fb17-375ddacb8e7a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               testo  letter_date  label\n",
              "0  Avendo ne giorni passati facto risposta a una ...         1450      0\n",
              "1  Dici non potest Vespasiane suavissime quantum ...         1450      0\n",
              "2  James cardinal of Papia greets Vespasian Dear ...         1444      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-be8e8dbd-62b5-4fdb-9346-afc1b1e84811\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>testo</th>\n",
              "      <th>letter_date</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Avendo ne giorni passati facto risposta a una ...</td>\n",
              "      <td>1450</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Dici non potest Vespasiane suavissime quantum ...</td>\n",
              "      <td>1450</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>James cardinal of Papia greets Vespasian Dear ...</td>\n",
              "      <td>1444</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-be8e8dbd-62b5-4fdb-9346-afc1b1e84811')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-be8e8dbd-62b5-4fdb-9346-afc1b1e84811 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-be8e8dbd-62b5-4fdb-9346-afc1b1e84811');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ],
      "source": [
        "df2['label'] = df2.letter_date.replace(label_dict)\n",
        "df2.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "9R-tVAhj228o"
      },
      "outputs": [],
      "source": [
        "# df3 = df2.sample(7000, random_state=1).copy()\n",
        "\n",
        "# df3 = df2.sample(23, random_state=1).copy()\n",
        "df3 = df2.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "MJp3XqPK3sE_",
        "outputId": "a22f3e6b-d2be-41bd-e261-78942b14ab54"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               testo  letter_date  label\n",
              "0  Avendo ne giorni passati facto risposta a una ...         1450      0\n",
              "1  Dici non potest Vespasiane suavissime quantum ...         1450      0\n",
              "2  James cardinal of Papia greets Vespasian Dear ...         1444      1\n",
              "3  Egli è più dì chio ricevetti una tua alla qual...         1449      2\n",
              "4  Honorevole come fratello et cetera Quanto più ...         1446      3"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b2e6f3f1-497b-4bf6-ab69-9fd2d0ecbb68\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>testo</th>\n",
              "      <th>letter_date</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Avendo ne giorni passati facto risposta a una ...</td>\n",
              "      <td>1450</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Dici non potest Vespasiane suavissime quantum ...</td>\n",
              "      <td>1450</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>James cardinal of Papia greets Vespasian Dear ...</td>\n",
              "      <td>1444</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Egli è più dì chio ricevetti una tua alla qual...</td>\n",
              "      <td>1449</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Honorevole come fratello et cetera Quanto più ...</td>\n",
              "      <td>1446</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b2e6f3f1-497b-4bf6-ab69-9fd2d0ecbb68')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b2e6f3f1-497b-4bf6-ab69-9fd2d0ecbb68 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b2e6f3f1-497b-4bf6-ab69-9fd2d0ecbb68');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ],
      "source": [
        "df3.reset_index(drop=True, inplace=True)\n",
        "df3.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x_PsTMaZ3yvC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aHyGuTFgyPO"
      },
      "source": [
        "## Data Preprocessing\n",
        "\n",
        "Machine Learning models don't work with raw text. We need to convert text to numbers (of some sort).\n",
        "\n",
        "Here are the requirements: \n",
        "\n",
        "- Add special tokens to separate sentences and do classification\n",
        "- Pass sequences of constant length (introduce padding)\n",
        "- Create array of 0s (pad token) and 1s (real token) called *attention mask*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "E7Mj-0ne--5t"
      },
      "outputs": [],
      "source": [
        "PRE_TRAINED_MODEL_NAME = 'bert-base-cased'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiLb-ltM-ZRz"
      },
      "source": [
        "Let's load a pre-trained [BertTokenizer](https://huggingface.co/transformers/model_doc/bert.html#berttokenizer):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "H3AfJSZ8NNLF"
      },
      "outputs": [],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfrSbwTQ-wi_"
      },
      "source": [
        "We'll use this text to understand the tokenization process:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "HZMitwrqm2eb"
      },
      "outputs": [],
      "source": [
        "sample_txt = 'When was I last outside? I am stuck at home for 2 weeks.'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yO2qBTVl_KPs"
      },
      "source": [
        "Some basic operations can convert the text to tokens and tokens to unique integers (ids):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTFhpHpsoWO7",
        "outputId": "992a4b56-3311-4f37-d6f2-1863fccaf00e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Sentence: When was I last outside? I am stuck at home for 2 weeks.\n",
            "   Tokens: ['When', 'was', 'I', 'last', 'outside', '?', 'I', 'am', 'stuck', 'at', 'home', 'for', '2', 'weeks', '.']\n",
            "Token IDs: [1332, 1108, 146, 1314, 1796, 136, 146, 1821, 5342, 1120, 1313, 1111, 123, 2277, 119]\n"
          ]
        }
      ],
      "source": [
        "tokens = tokenizer.tokenize(sample_txt)\n",
        "token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "print(f' Sentence: {sample_txt}')\n",
        "print(f'   Tokens: {tokens}')\n",
        "print(f'Token IDs: {token_ids}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzbbKLR8lZbu"
      },
      "source": [
        "### Special Tokens\n",
        "\n",
        "`[SEP]` - marker for ending of a sentence\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXwz47bQvCbc",
        "outputId": "cc16b0b1-518e-4a3a-83b9-f36ceee9538c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('[SEP]', 102)"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ],
      "source": [
        "tokenizer.sep_token, tokenizer.sep_token_id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mip_eGeXwLFF"
      },
      "source": [
        "`[CLS]` - we must add this token to the start of each sentence, so BERT knows we're doing classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6K4it5HwE6l",
        "outputId": "07098bb9-51d6-4363-d7af-772c3a2aff40"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('[CLS]', 101)"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ],
      "source": [
        "tokenizer.cls_token, tokenizer.cls_token_id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qi6O-yEY09gl"
      },
      "source": [
        "There is also a special token for padding:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vx7gD5xf1AFK",
        "outputId": "81ec5360-ea7a-4f2b-80b1-5d73536b1110"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('[PAD]', 0)"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ],
      "source": [
        "tokenizer.pad_token, tokenizer.pad_token_id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GWCfijM0TWB"
      },
      "source": [
        "BERT understands tokens that were in the training set. Everything else can be encoded using the `[UNK]` (unknown) token:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cmfFsbEKQDT",
        "outputId": "dc23d383-e0f7-49c8-f1a4-e7cebeec859d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('[UNK]', 100)"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ],
      "source": [
        "tokenizer.unk_token, tokenizer.unk_token_id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9ap7jdL0LYU"
      },
      "source": [
        "All of that work can be done using the [`encode_plus()`](https://huggingface.co/transformers/main_classes/tokenizer.html#transformers.PreTrainedTokenizer.encode_plus) method:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vea9edaaxSPO",
        "outputId": "af5e3c47-0419-42a8-ffc0-b9e930c88677"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:2336: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'attention_mask'])"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ],
      "source": [
        "encoding = tokenizer.encode_plus(\n",
        "  sample_txt,\n",
        "  max_length=256,\n",
        "  add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
        "  return_token_type_ids=False,\n",
        "  pad_to_max_length=True,\n",
        "  return_attention_mask=True,\n",
        "  return_tensors='pt',  # Return PyTorch tensors\n",
        ")\n",
        "\n",
        "encoding.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sS69c8WvdOED"
      },
      "source": [
        "The token ids are now stored in a Tensor and padded to a length of 32:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YzBmcOla0yQR",
        "outputId": "8dcf2eb2-52e8-4bc8-949f-8000bb1b22ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "256\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 101, 1332, 1108,  146, 1314, 1796,  136,  146, 1821, 5342, 1120, 1313,\n",
              "        1111,  123, 2277,  119,  102,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0])"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ],
      "source": [
        "print(len(encoding['input_ids'][0]))\n",
        "encoding['input_ids'][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itAyVPsNdyc1"
      },
      "source": [
        "The attention mask has the same length:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wiv5LLiw03Ox",
        "outputId": "d452108b-99c9-4040-c108-c6b0ac32a467"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "256\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ],
      "source": [
        "print(len(encoding['attention_mask'][0]))\n",
        "encoding['attention_mask']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1RvhC4jNHHy"
      },
      "source": [
        "We can inverse the tokenization to have a look at the special tokens:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IagGoafKLUwW",
        "outputId": "224d21bb-9929-4d4d-aecb-f1bd8b6a485b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS]',\n",
              " 'When',\n",
              " 'was',\n",
              " 'I',\n",
              " 'last',\n",
              " 'outside',\n",
              " '?',\n",
              " 'I',\n",
              " 'am',\n",
              " 'stuck',\n",
              " 'at',\n",
              " 'home',\n",
              " 'for',\n",
              " '2',\n",
              " 'weeks',\n",
              " '.',\n",
              " '[SEP]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]']"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ],
      "source": [
        "tokenizer.convert_ids_to_tokens(encoding['input_ids'][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "waKjYxTDuaWt"
      },
      "source": [
        "### Choosing Sequence Length\n",
        "\n",
        "BERT works with fixed-length sequences. We'll use a simple strategy to choose the max length. Let's store the token length of each review:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "BUnE5CT9hbeZ"
      },
      "outputs": [],
      "source": [
        "token_lens = []\n",
        "\n",
        "for txt in df3.testo:\n",
        "  tokens = tokenizer.encode(txt, max_length=256)\n",
        "  token_lens.append(len(tokens))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tI4goUrHf6da"
      },
      "source": [
        "and plot the distribution:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "SzE1j4jxmUtd"
      },
      "outputs": [],
      "source": [
        "# sns.distplot(token_lens)\n",
        "# plt.xlim([0, 256]);\n",
        "# plt.xlabel('Token count');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oW6ajl30t6du"
      },
      "source": [
        "Most of the reviews seem to contain less than 128 tokens, but we'll be on the safe side and choose a maximum length of 160."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "t7xSmJtLuoxW"
      },
      "outputs": [],
      "source": [
        "MAX_LEN = 256"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvvcoU6nurHy"
      },
      "source": [
        "We have all building blocks required to create a PyTorch dataset. Let's do it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "E2BPgRJ7YBK0"
      },
      "outputs": [],
      "source": [
        "class GPReviewDataset(Dataset):\n",
        "\n",
        "  def __init__(self, reviews, targets, tokenizer, max_len):\n",
        "    self.reviews = reviews\n",
        "    self.targets = targets\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.reviews)\n",
        "  \n",
        "  def __getitem__(self, item):\n",
        "    review = str(self.reviews[item])\n",
        "    target = self.targets[item]\n",
        "\n",
        "    encoding = self.tokenizer.encode_plus(\n",
        "      review,\n",
        "      add_special_tokens=True,\n",
        "      max_length=self.max_len,\n",
        "      return_token_type_ids=False,\n",
        "      pad_to_max_length=True,\n",
        "      return_attention_mask=True,\n",
        "      return_tensors='pt',\n",
        "    )\n",
        "\n",
        "    return {\n",
        "      'review_text': review,\n",
        "      'input_ids': encoding['input_ids'].flatten(),\n",
        "      'attention_mask': encoding['attention_mask'].flatten(),\n",
        "      'targets': torch.tensor(target, dtype=torch.long)\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2uwsvCYqDJK"
      },
      "source": [
        "The tokenizer is doing most of the heavy lifting for us. We also return the review texts, so it'll be easier to evaluate the predictions from our model. Let's split the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "B-vWzoo81dvO"
      },
      "outputs": [],
      "source": [
        "df_train, df_test = train_test_split(df3, test_size=0.1, random_state=RANDOM_SEED)\n",
        "df_val, df_test = train_test_split(df_test, test_size=0.5, random_state=RANDOM_SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xz3ZOQXVPCwh",
        "outputId": "a67dcceb-9ba9-4fce-ca66-750d0745169a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((20, 3), (1, 3), (2, 3))"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ],
      "source": [
        "df_train.shape, df_val.shape, df_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4tQ1x-vqNab"
      },
      "source": [
        "We also need to create a couple of data loaders. Here's a helper function to do it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "KEGqcvkuOuTX"
      },
      "outputs": [],
      "source": [
        "def create_data_loader(df3, tokenizer, max_len, batch_size):\n",
        "  ds = GPReviewDataset(\n",
        "    reviews=df3.testo.to_numpy(),\n",
        "    targets=df3.label.to_numpy(),\n",
        "    tokenizer=tokenizer,\n",
        "    max_len=max_len\n",
        "  )\n",
        "\n",
        "  return DataLoader(\n",
        "    ds,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=4\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "vODDxMKsPHqI"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 16\n",
        "\n",
        "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "test_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6dlOptwqlhF"
      },
      "source": [
        "Let's have a look at an example batch from our training data loader:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y93ldSN47FeT",
        "outputId": "f6fa91cf-763c-41aa-d565-eb0a6437a063",
        "pycharm": {
          "is_executing": true
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['review_text', 'input_ids', 'attention_mask', 'targets'])"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ],
      "source": [
        "data = next(iter(train_data_loader))\n",
        "data.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IdU4YVqb7N8M",
        "outputId": "7efd9e70-53b3-4cfe-a1d4-da802ab8f8d0",
        "pycharm": {
          "is_executing": true
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16])\n"
          ]
        }
      ],
      "source": [
        "print(data['input_ids'].shape)\n",
        "print(data['attention_mask'].shape)\n",
        "print(data['targets'].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H63Y-TjyRC7S"
      },
      "source": [
        "## Date Classification with BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "440Nd31VTHER"
      },
      "source": [
        "There are a lot of helpers that make using BERT easy with the Transformers library. Depending on the task you might want to use [BertForSequenceClassification](https://huggingface.co/transformers/model_doc/bert.html#bertforsequenceclassification), [BertForQuestionAnswering](https://huggingface.co/transformers/model_doc/bert.html#bertforquestionanswering) or something else. \n",
        "\n",
        "But who cares, right? We're *hardcore*! We'll use the basic [BertModel](https://huggingface.co/transformers/model_doc/bert.html#bertmodel) and build our Date classifier on top of it. Let's load the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0P41FayISNRI",
        "outputId": "7232f0a0-7678-480e-ebad-0f5841e775f6",
        "pycharm": {
          "is_executing": true
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "bert_model = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFE7YSbFdY4t"
      },
      "source": [
        "And try to use it on the encoding of our sample text:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "s1aoFxbQSn15",
        "pycharm": {
          "is_executing": true
        }
      },
      "outputs": [],
      "source": [
        "last_hidden_state, pooled_output = bert_model(\n",
        "  input_ids=encoding['input_ids'], \n",
        "  attention_mask=encoding['attention_mask'],\n",
        "  return_dict = False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLLu8zmqbaHV"
      },
      "source": [
        "The `last_hidden_state` is a sequence of hidden states of the last layer of the model. Obtaining the `pooled_output` is done by applying the [BertPooler](https://github.com/huggingface/transformers/blob/edf0582c0be87b60f94f41c659ea779876efc7be/src/transformers/modeling_bert.py#L426) on `last_hidden_state`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUJHXNpIbcci",
        "outputId": "358fcd05-d449-4321-8c1d-b1deb5280d90",
        "pycharm": {
          "is_executing": true
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 256, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ],
      "source": [
        "last_hidden_state.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5z2k5e_uB9mU",
        "pycharm": {
          "is_executing": true
        }
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4dAot4zbz8k"
      },
      "source": [
        "We have the hidden state for each of our 32 tokens (the length of our example sequence). But why 768? This is the number of hidden units in the feedforward-networks. We can verify that by checking the config:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsxB7Qy7b5YN",
        "outputId": "4dbd9f23-0da0-4460-85c8-f574ba2834de",
        "pycharm": {
          "is_executing": true
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ],
      "source": [
        "bert_model.config.hidden_size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTKi8-rTd_j4"
      },
      "source": [
        "\n",
        "\n",
        "You can think of the `pooled_output` as a summary of the content, according to BERT. Albeit, you might try and do better. Let's look at the shape of the output:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jIAtRhaSz9c",
        "outputId": "6408ba7a-e71c-4282-a4e6-25f83b8e2837",
        "pycharm": {
          "is_executing": true
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ],
      "source": [
        "pooled_output.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0o_NiS3WgOFf"
      },
      "source": [
        "We can use all of this knowledge to create a classifier that uses the BERT model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "m_mRflxPl32F",
        "pycharm": {
          "is_executing": true
        }
      },
      "outputs": [],
      "source": [
        "class DateClassifier(nn.Module):\n",
        "\n",
        "  def __init__(self, n_classes):\n",
        "    super(DateClassifier, self).__init__()\n",
        "    self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
        "    self.drop = nn.Dropout(p=0.3)\n",
        "    self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
        "  \n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    _, pooled_output = self.bert(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask,\n",
        "      return_dict = False\n",
        "    )\n",
        "    output = self.drop(pooled_output)\n",
        "    return self.out(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJg8m3NQJahc"
      },
      "source": [
        "Our classifier delegates most of the heavy lifting to the BertModel. We use a dropout layer for some regularization and a fully-connected layer for our output. Note that we're returning the raw output of the last layer since that is required for the cross-entropy loss function in PyTorch to work.\n",
        "\n",
        "This should work like any other PyTorch model. Let's create an instance and move it to the GPU:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0yQnuSFsjDp",
        "outputId": "32eaca2d-207d-4efa-ba45-5fa603af7285",
        "pycharm": {
          "is_executing": true
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "model = DateClassifier(len(class_names))\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCPCFDLlKIQd"
      },
      "source": [
        "We'll move the example batch of our training data to the GPU:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "mz7p__CqdaMO",
        "pycharm": {
          "is_executing": true
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c29f60a-a74a-4eff-9f43-31d5160180d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n"
          ]
        }
      ],
      "source": [
        "input_ids = data['input_ids'].to(device)\n",
        "attention_mask = data['attention_mask'].to(device)\n",
        "\n",
        "print(input_ids.shape) # batch size x seq length\n",
        "print(attention_mask.shape) # batch size x seq length"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hr1EgkEtKOIB"
      },
      "source": [
        "To get the predicted probabilities from our trained model, we'll apply the softmax function to the outputs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rTCj46Zamry",
        "outputId": "479aa6fd-4cf8-4841-daa2-5a2c9d2f3577",
        "pycharm": {
          "is_executing": true
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0691, 0.1863, 0.1053, 0.4669, 0.1723],\n",
              "        [0.0994, 0.1947, 0.1793, 0.3970, 0.1297],\n",
              "        [0.1236, 0.1337, 0.1675, 0.4528, 0.1223],\n",
              "        [0.0456, 0.1262, 0.0810, 0.5906, 0.1565],\n",
              "        [0.1832, 0.1180, 0.0978, 0.4851, 0.1159],\n",
              "        [0.0757, 0.1607, 0.1260, 0.4324, 0.2052],\n",
              "        [0.0867, 0.1262, 0.1452, 0.4583, 0.1836],\n",
              "        [0.1182, 0.0956, 0.1459, 0.4599, 0.1804],\n",
              "        [0.1267, 0.0802, 0.1664, 0.4462, 0.1805],\n",
              "        [0.0879, 0.0767, 0.1503, 0.5573, 0.1279],\n",
              "        [0.0743, 0.0627, 0.1310, 0.6326, 0.0994],\n",
              "        [0.1153, 0.0867, 0.1926, 0.3812, 0.2242],\n",
              "        [0.0380, 0.0981, 0.0776, 0.6592, 0.1272],\n",
              "        [0.0586, 0.0859, 0.1161, 0.5785, 0.1609],\n",
              "        [0.0854, 0.1032, 0.1744, 0.5238, 0.1132],\n",
              "        [0.0453, 0.1558, 0.1859, 0.4581, 0.1549]], device='cuda:0',\n",
              "       grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ],
      "source": [
        "F.softmax(model(input_ids, attention_mask), dim=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9xikRdtRN1N"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76g7FV85H-T8"
      },
      "source": [
        "To reproduce the training procedure from the BERT paper, we'll use the [AdamW](https://huggingface.co/transformers/main_classes/optimizer_schedules.html#adamw) optimizer provided by Hugging Face. It corrects weight decay, so it's similar to the original paper. We'll also use a linear scheduler with no warmup steps:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5v-ArJ2fCCcU",
        "outputId": "0d4c28ca-7365-4613-844b-905908716922",
        "pycharm": {
          "is_executing": true
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
        "total_steps = len(train_data_loader) * EPOCHS\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "  optimizer,\n",
        "  num_warmup_steps=0,\n",
        "  num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8522g7JIu5J"
      },
      "source": [
        "How do we come up with all hyperparameters? The BERT authors have some recommendations for fine-tuning:\n",
        "\n",
        "- Batch size: 16, 32\n",
        "- Learning rate (Adam): 5e-5, 3e-5, 2e-5\n",
        "- Number of epochs: 2, 3, 4\n",
        "\n",
        "We're going to ignore the number of epochs recommendation but stick with the rest. Note that increasing the batch size reduces the training time significantly, but gives you lower accuracy.\n",
        "\n",
        "Let's continue with writing a helper function for training our model for one epoch:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "bzl9UhuNx1_Q",
        "pycharm": {
          "is_executing": true
        }
      },
      "outputs": [],
      "source": [
        "def train_epoch(\n",
        "  model, \n",
        "  data_loader, \n",
        "  loss_fn, \n",
        "  optimizer, \n",
        "  device, \n",
        "  scheduler, \n",
        "  n_examples\n",
        "):\n",
        "  model = model.train()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "  \n",
        "  for d in data_loader:\n",
        "    input_ids = d[\"input_ids\"].to(device)\n",
        "    attention_mask = d[\"attention_mask\"].to(device)\n",
        "    targets = d[\"targets\"].to(device)\n",
        "\n",
        "    outputs = model(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    loss = loss_fn(outputs, targets)\n",
        "\n",
        "    correct_predictions += torch.sum(preds == targets)\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    loss.backward()\n",
        "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4PniYIte0fr"
      },
      "source": [
        "Training the model should look familiar, except for two things. The scheduler gets called every time a batch is fed to the model. We're avoiding exploding gradients by clipping the gradients of the model using [clip_grad_norm_](https://pytorch.org/docs/stable/nn.html#clip-grad-norm).\n",
        "\n",
        "Let's write another one that helps us evaluate the model on a given data loader:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "CXeRorVGIKre",
        "pycharm": {
          "is_executing": true
        }
      },
      "outputs": [],
      "source": [
        "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
        "  model = model.eval()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      targets = d[\"targets\"].to(device)\n",
        "\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "      loss = loss_fn(outputs, targets)\n",
        "\n",
        "      correct_predictions += torch.sum(preds == targets)\n",
        "      losses.append(loss.item())\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_rdSDBHhhCh"
      },
      "source": [
        "Using those two, we can write our training loop. We'll also store the training history:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1zhHoFNsxufs",
        "outputId": "628965eb-891b-48a1-898e-8c7cbcd5a6f0",
        "pycharm": {
          "is_executing": true
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "----------\n",
            "Train loss 1.7456371188163757 accuracy 0.2\n",
            "Val   loss 1.6755375862121582 accuracy 0.0\n",
            "\n",
            "Epoch 2/10\n",
            "----------\n",
            "Train loss 1.6208587884902954 accuracy 0.1\n",
            "Val   loss 2.2240989208221436 accuracy 0.0\n",
            "\n",
            "Epoch 3/10\n",
            "----------\n",
            "Train loss 1.6637616157531738 accuracy 0.2\n",
            "Val   loss 1.7511587142944336 accuracy 0.0\n",
            "\n",
            "Epoch 4/10\n",
            "----------\n",
            "Train loss 1.6102489829063416 accuracy 0.2\n",
            "Val   loss 1.4645501375198364 accuracy 0.0\n",
            "\n",
            "Epoch 5/10\n",
            "----------\n",
            "Train loss 1.6097670793533325 accuracy 0.30000000000000004\n",
            "Val   loss 1.4096746444702148 accuracy 0.0\n",
            "\n",
            "Epoch 6/10\n",
            "----------\n",
            "Train loss 1.554444670677185 accuracy 0.35000000000000003\n",
            "Val   loss 1.3177765607833862 accuracy 0.0\n",
            "\n",
            "Epoch 7/10\n",
            "----------\n",
            "Train loss 1.5595288276672363 accuracy 0.30000000000000004\n",
            "Val   loss 1.3790167570114136 accuracy 0.0\n",
            "\n",
            "Epoch 8/10\n",
            "----------\n",
            "Train loss 1.4235196113586426 accuracy 0.4\n",
            "Val   loss 1.4488608837127686 accuracy 0.0\n",
            "\n",
            "Epoch 9/10\n",
            "----------\n",
            "Train loss 1.5573996305465698 accuracy 0.2\n",
            "Val   loss 1.5082870721817017 accuracy 0.0\n",
            "\n",
            "Epoch 10/10\n",
            "----------\n",
            "Train loss 1.5545151233673096 accuracy 0.25\n",
            "Val   loss 1.5316892862319946 accuracy 0.0\n",
            "\n",
            "CPU times: user 2.89 s, sys: 4.78 s, total: 7.67 s\n",
            "Wall time: 9.07 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "history = defaultdict(list)\n",
        "best_accuracy = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "  print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
        "  print('-' * 10)\n",
        "\n",
        "  train_acc, train_loss = train_epoch(\n",
        "    model,\n",
        "    train_data_loader,    \n",
        "    loss_fn, \n",
        "    optimizer, \n",
        "    device, \n",
        "    scheduler, \n",
        "    len(df_train)\n",
        "  )\n",
        "\n",
        "  print(f'Train loss {train_loss} accuracy {train_acc}')\n",
        "\n",
        "  val_acc, val_loss = eval_model(\n",
        "    model,\n",
        "    val_data_loader,\n",
        "    loss_fn, \n",
        "    device, \n",
        "    len(df_val)\n",
        "  )\n",
        "\n",
        "  print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
        "  print()\n",
        "\n",
        "  history['train_acc'].append(train_acc)\n",
        "  history['train_loss'].append(train_loss)\n",
        "  history['val_acc'].append(val_acc)\n",
        "  history['val_loss'].append(val_loss)\n",
        "\n",
        "  if val_acc > best_accuracy:\n",
        "    torch.save(model.state_dict(), 'best_model_state.bin')\n",
        "    best_accuracy = val_acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4r8-5zWsiVur"
      },
      "source": [
        "Note that we're storing the state of the best model, indicated by the highest validation accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLQf52c7fbzr"
      },
      "source": [
        "Whoo, this took some time! We can look at the training vs validation accuracy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-FWG7kBm372V",
        "pycharm": {
          "is_executing": true
        }
      },
      "outputs": [],
      "source": [
        "# plt.plot(history['train_acc'], label='train accuracy')\n",
        "# plt.plot(history['val_acc'], label='validation accuracy')\n",
        "\n",
        "# plt.title('Training history')\n",
        "# plt.ylabel('Accuracy')\n",
        "# plt.xlabel('Epoch')\n",
        "# plt.legend()\n",
        "# plt.ylim([0, 1]);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsHqkLAuf8pv"
      },
      "source": [
        "The training accuracy starts to approach 100% after 10 epochs or so. You might try to fine-tune the parameters a bit more, but this will be good enough for us.\n",
        "\n",
        "Don't want to wait? Uncomment the next cell to download my pre-trained model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zoGUH8VZ-pPQ"
      },
      "outputs": [],
      "source": [
        "# # !gdown --id 1V8itWtowCYnb2Bc9KlK9SxGff9WwmogA\n",
        "\n",
        "# model = DateClassifier(len(class_names))\n",
        "# model.load_state_dict(torch.load('/content/drive/MyDrive/Colab Notebooks/dati/Models/best_model_state.bin'))\n",
        "# model.load_state_dict(torch.load('./data_volume/finetuned_BERT_epoch_1.model'))\n",
        "# model = model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3HZb3NWFtFf"
      },
      "source": [
        "## Evaluation\n",
        "\n",
        "So how good is our model on predicting Date? Let's start by calculating the accuracy on the test data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jS3gJ_qBEljD",
        "outputId": "a2282c32-ef2e-489b-b1e6-edfd3fe6db41",
        "pycharm": {
          "is_executing": true
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ],
      "source": [
        "test_acc, _ = eval_model(\n",
        "  model,\n",
        "  test_data_loader,\n",
        "  loss_fn,\n",
        "  device,\n",
        "  len(df_test)\n",
        ")\n",
        "\n",
        "test_acc.item()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdQ7-ylCj8Gd"
      },
      "source": [
        "The accuracy is about 1% lower on the test set. Our model seems to generalize well.\n",
        "\n",
        "We'll define a helper function to get the predictions from our model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "id": "EgR6MuNS8jr_",
        "pycharm": {
          "is_executing": true
        }
      },
      "outputs": [],
      "source": [
        "def get_predictions(model, data_loader):\n",
        "  model = model.eval()\n",
        "  \n",
        "  review_texts = []\n",
        "  predictions = []\n",
        "  prediction_probs = []\n",
        "  real_values = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "\n",
        "      texts = d[\"review_text\"]\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      targets = d[\"targets\"].to(device)\n",
        "\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "      probs = F.softmax(outputs, dim=1)\n",
        "\n",
        "      review_texts.extend(texts)\n",
        "      predictions.extend(preds)\n",
        "      prediction_probs.extend(probs)\n",
        "      real_values.extend(targets)\n",
        "\n",
        "  predictions = torch.stack(predictions).cpu()\n",
        "  prediction_probs = torch.stack(prediction_probs).cpu()\n",
        "  real_values = torch.stack(real_values).cpu()\n",
        "  return review_texts, predictions, prediction_probs, real_values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkbnBTI7kd_y"
      },
      "source": [
        "This is similar to the evaluation function, except that we're storing the text of the reviews and the predicted probabilities (by applying the softmax on the model outputs):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "id": "zHdPZr60-0c_",
        "pycharm": {
          "is_executing": true
        }
      },
      "outputs": [],
      "source": [
        "y_review_texts, y_pred, y_pred_probs, y_test = get_predictions(\n",
        "  model,\n",
        "  test_data_loader\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVwoVij2lC7F"
      },
      "source": [
        "Let's have a look at the classification report. Here I face problems which I think it is becaues of poor model. I think because I do not have enough data. I try with another dataset. with more entries for training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "L8a9_8-ND3Is",
        "outputId": "d297aad8-d4bb-4bf8-a715-d1dc39072357",
        "pycharm": {
          "is_executing": true
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-140-826037adbc29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2130\u001b[0m             )\n\u001b[1;32m   2131\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2132\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   2133\u001b[0m                 \u001b[0;34m\"Number of classes, {0}, does not match size of \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2134\u001b[0m                 \u001b[0;34m\"target_names, {1}. Try specifying the labels \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Number of classes, 3, does not match size of target_names, 5. Try specifying the labels parameter"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test, y_pred, target_names=class_names))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3.8.10 ('torchBERT_env')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "73a1920b6a582509ff5ca42142f361dc1a783dbb47d7e906e137f97655458260"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}